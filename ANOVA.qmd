---
title: "ANOVA"
format: html
editor: visual
---

## One-Way ANOVA

ANOVA (Analysis of Variance) is mainly used when your independent variable(s) are categorical and your dependent variable is continuous (numerical).

So, in short:

Independent variable(s): Categorical (e.g., gender, treatment type, region, etc.)

Dependent variable: Continuous (e.g., income, test scores, height, etc.)

### What does ANOVA test?

ANOVA tests whether the means of the dependent variable differ significantly across the levels (groups) of the categorical variable.

Example:

Suppose you want to know if average exam scores differ across 3 teaching methods (Method A, Method B, Method C).

**Teaching method** ‚Üí categorical (independent variable)

**Exam score** ‚Üí continuous (dependent variable)

‚úîÔ∏è ANOVA is suitable here.

### ASSUMPTIONS

**Normality** - each sample is taken from a normally distributed population. **Independance** - each sample has been drawn independently of the other samples. **Equal variance** - variance of data in the different groups should be the same.

```{r}
 library(dplyr)
library(tidyverse)

 data(iris)
 dat <- iris %>%
 select(Species, Sepal.Length)
 summary(dat)
```

### 

```{r}
iris %>% 
  group_by(Species) %>% 
  summarize (count_species =n(),
             mean_speal_length =mean(Sepal.Length,na.rm=TRUE),
             sd_sepal_length =sd(Sepal.Length,na.rm = TRUE)
             )
```

```{r}
ggplot(iris, aes(x = Species, y = Sepal.Length)) + 
geom_boxplot()
```

```{r}
one_way_anova <- aov(Sepal.Length ~ Species , data = iris)
 summary(one_way_anova)
```

P ‚àíValue \< 0.05. So, we reject H0. We can conclude that, there is a statistical difference between the mean of the sepal length according to the type of the iris plant at 5% level of significance.

#### Multiple Comparisons (POST-HOC TESTS)

If the test rejects H0 , the one-way ANOVA test does not inform which group has a different mean. Then run a pairwise t-test for multiple comparison and identify the different groups.

```{r}
pairwise.t.test(iris$Sepal.Length,iris$Species,p.adj="bonferroni")
```

-   Based on P-values \< 0.05, all the three species combinations are differ according to the Sepal Length.

-   There are several possible adjustment methods: ‚Äú**bonferroni**‚Äù, ‚Äú**holm**‚Äù, ‚Äú**hochberg**‚Äù, ‚Äú**hommel**‚Äù, ‚Äú**BH**‚Äù

-   Tukey‚Äôs Honest Significant Differences (Tukey‚Äôs HSD) is also a very common test that we can use for multiple comparisons. It requires an anova object.

    ```{r}
    pairwise.t.test(iris$Sepal.Length,iris$Species,p.adj="holm")
    ```

    ```{r}
    TukeyHSD(one_way_anova)
    ```

### Check Normality Assumptions

### **Normality**

1.  **Analyzing the ANOVA model residuals** to check the normality for all groups together. This approach is easier and it‚Äôs very handy when you have many groups or if there are few data points per group.

    Normality of residuals can be tested visually via a QQ-plot, and/or formally via a normality test (Shapiro-Wilk test).

    ```{r}
    library(car)
    qqPlot(one_way_anova$residuals,id=FALSE)
    ```

H0 : data come from a normal distribution

H1 : data do not come from a normal distribution.

```{r}
shapiro.test(one_way_anova$residuals)

# p value > 0.05 and we do not reject H0 and conclude that the residulas follow approximately a normal distibution at 5% level of sgnificance.

```

1.  **Check normality for each group separately**. This approach might be used when you have only a few groups and many data points per group.

    ```{r}
    iris %>% 
      group_by(Species) %>%
      summarize(statistic =shapiro.test(Sepal.Length)$statistic,
                p.value =shapiro.test(Sepal.Length)$p.value
                )
    ```

### HOMOGENEITY OF VARIANCES

*The result will have an impact on whether we use the ANOVA or the Welch ANOVA.*

We can formally test for equality of the variances with a **Levene‚Äôs** or **Bartle ‚Äôs** test. Notice that the **Levene‚Äôs test** is less sensitive to departures from normal distribution than the **Bartle ‚Äôs test**.

H0 : Variance are equal

H1 : at least one Variance is different

```{r}
bartlett.test(Sepal.Length~Species,data = iris)
```

```{r}
leveneTest(Sepal.Length~Species,data = iris)
```

**Welch One-Way ANOVA**

The Welch One ANOVA test is an alternative to the standard one way ANOVA in the situation where the homogeneity of variance cant be assumed.

```{r}
library(rstatix)

waov <- iris %>%
  welch_anova_test(Sepal.Length ~ Species)
waov
  
```

In this case ,the **Games -Howell post hoc test** or **Paiwise t-test** can be used to compare all possible combinations of group differences.

```{r}
pwc2 <- iris %>% games_howell_test(Sepal.Length ~ Species)
pwc2
```

```{r}
pwc3 <- iris %>%
  pairwise_t_test(
    Sepal.Length ~Species ,pool.sd = FALSE,
    p.adjust.method = "bonferroni"
  )
pwc3
```

## Two-Way ANOVA

Two-Way ANOVA is an extension of One-Way ANOVA, used to examine the effect of two independent categorical variables on one continuous dependent variable ‚Äî and also their interaction effect.

When to use Two-Way ANOVA:

-   You have two categorical independent variables (factors)

-   You have one continuous dependent variable.

-   You want to test:

1.  Main effect of Factor A

2.  Main effect of Factor B

3.  Interaction effect (A √ó B)

#### example :

```{r}
#install.packages("rstatix")
library(rstatix)
library(datarium)
library(dplyr)

data("jobsatisfaction")
attach(jobsatisfaction)

jobsatisfaction %>%
  group_by(gender,education_level) %>%
  get_summary_stats(score,type = "mean_sd")
```

```{r}
table(jobsatisfaction$gender,jobsatisfaction$education_level)
```

```{r}

library(car)

 score.lm <- lm(formula = score ~ gender + education_level,data = jobsatisfaction)
 score.II.aov <- Anova(score.lm, type = 2)
 score.II.aov

```

#### Next try to Interaction of gender \* education_level

```{r}
score.lm.int <- lm(formula = score ~ gender * education_level ,data = jobsatisfaction)
 
 score.II.aov2 <- Anova(score.lm.int, type = 2)
 score.II.aov2
```

## Checking Assumptions

### 1. Normality

#### QQ Plots for normality.

```{r}
library(car)

qqPlot(score.lm.int$residuals , id =FALSE )
```

#### Shapiro Test for Normality

```{r}
shapiro.test(score.lm.int$residuals)
```

```{r}
library(dplyr)

jobsatisfaction %>% 
  group_by(gender ,education_level) %>%
  summarize(statistic =shapiro.test(score)$statistic,
            p.value = shapiro.test(score)$p.value)
```

### 2. Homogeneity Of Variances

```{r}
bartlett.test(score ~interaction(gender , education_level),data = jobsatisfaction)

```

```{r}
leveneTest(score ~ gender * education_level, data = jobsatisfaction)
```

### POST-HOC TESTS IN TWO-WAY ANOVA

### 1. What does an **interaction** mean?

If the interaction is significant, it means:\
üëâ *The effect of one factor depends on the level of the other factor.*

Example:

-   Suppose Factor A = **teaching method** (Traditional, Online).

-   Factor B = **gender** (Male, Female).

-   Outcome = **test score**.

If there‚Äôs an interaction:

-   The teaching method effect might be **strong for males but weak for females** (or vice versa).

```         
### 2. What to do next?

We don‚Äôt stop at ‚Äúinteraction is significant‚Äù. We **break it down**:

-    **Simple main effect**:\
    Look at Factor A‚Äôs effect **within each level** of Factor B.\
    (e.g., compare Traditional vs Online **separately for males**, and then **separately for females**).

-    **Simple pairwise comparisons**:\
    If the simple main effect is significant, do **pairwise comparisons** to see *exactly which groups differ*.\
    (e.g., for females, maybe Online is much higher than Traditional; for males, no difference).
```

```{r}
### 1 step : group the data by gender and fit anove


model <- lm(score ~ gender * education_level ,data =jobsatisfaction)

jobsatisfaction %>%
  group_by(gender) %>%
  anova_test(score ~education_level ,error =model)
```

```{r}
 ## If first step is significant , then try step 2


## Step 2 : Pairwise Comparisons

library(emmeans)

pwc <- jobsatisfaction %>%
  group_by(gender) %>%
  emmeans_test(score ~education_level ,p.adjust.method = 'bonferroni')

pwc
```

There was a significant difference of job satisfaction score between all groups for both males and females.

If the two-way interaction is not statistically significant, you need to consult the main effect for each of the two variables (gender and education_level) in the ANOVA output

##### example 2

```{r}
score.II.aov2
```

The main effect of gender was not significant.

Perform pairwise comparisons between education level groups to determine which groups are significantly different.

```{r}
pairwise.t.test(jobsatisfaction$score ,jobsatisfaction$education_level ,p.adjust.method = 'bonferroni')
```

or we can use

```{r}
jobsatisfaction %>%
  pairwise_t_test(score ~education_level,
                  p.adjust.method = 'bonferroni')
```

All pairwise differences were statistically significant (p \<0.05)
